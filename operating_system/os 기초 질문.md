# 운영체제

### 운영체제

- 운영체제란?
    
    시스템의 자원과 동작을 관리하는 소프트웨어입니다. 하드웨어, 네트워킹, 저장장치, 프로세스 등을 관리합니다. 
    
- 운영체제의 역할
    1. CPU 스케줄링과 프로세스 관리 : CPU 소유권을 어떤 프로세스에 할당할지, 프로세스의 생성과 삭제, 자원 할당 및 반환을 관리합니다.
    2. 메모리 관리 : 한정된 메모리를 어떤 프로세스가 얼마나 메모리를 할당할지 관리합니다.
    3. 디스크 파일 관리 : 디스크 파일을 어떤 방법으로 보관할지 관리합니다. (페이징 같은거)
    4. I/O 디바이스 관리 : 마우스와 키보드와 같은 I/O 디바이스들 간에 데이터를 주고 받는 것을 관리합니다.
- 운영체제의 구조    
    - 시스템 콜 :
        - 커널에서 제공하는 서비스를 이용하기 위한 인터페이스
        - 사용자 모드에서 실행되는 프로그램이 커널 모드에서 실행되는 운영체제 기능을 사용할 수 있도록 함.
    - 커널 :
        - 하드웨어와 소프트웨어 간의 중재 역할을 수행.
        - 하드웨어를 효율적으로 관리
    - 드라이버 :
        - 하드웨어 장치와 운영체제 간의 통신을 담당하는 소프트웨어
    - 인터페이스로 구현했을 때 장점?
        
        네트워크 통신이나 데이터베이스와 같은 낮은 단계의 영역 처리에 대해 신경쓰지 않고 어플리케이션 개발 가능하다.
        
    - 유저 모드에서 파일을 읽지 않고, 커널 모드로 들어가 파일을 읽는 이유?
        
        컴퓨터의 자원에 직접적인 접근을 차단하여 프로그램을 다른 프로그램으로부터 보호한다.
        
    - (참고) modebit
                
    
- CPU
    - 컴퓨터의 **중앙 연산 장치**로, 모든 명령을 처리하고 컴퓨터의 동작을 제어하는 핵심 하드웨어
    

### 메모리

- 메모리 계층
        
    레지스터 : CPU 내부에 있는 작은 메모리, 휘발성, 속도가 빠름, 용량이 가장 작음
    
    캐시 : 휘발성, 속도 빠름, 용량 작음
    
    RAM : 휘발성, 속도 보통, 용량 보통
    
    SSD : 비휘발성, 속도 느림, 용량 큼
    
- 캐시에 대해 설명해주세요.
    
    메모리와 CPU 사이의 속도 차이로 인해 병목현상으로 인한 비효율성이 발생한다.
    
    이를 해결하기 위해 중간에 캐시를 두어 자주 조회되는 되는 데이터를 저장하여 병목현상을 방지한다.
    
    - 캐시 히트 / 캐시 미스에 대해 설명해주세요.
        
        캐시는 CPU와 메모리 간 속도 차이를 줄이기 위해 도입된 고속 메모리 계층입니다.
        
        CPU가 데이터를 요청할 때, 해당 데이터가 캐시에 있다면 캐시 히트가 발생하여 매우 빠르게 처리됩니다. 반면, 캐시에 데이터가 없으면 캐시 미스가 발생하며, 메모리에서 데이터를 가져와야 하므로 처리 속도가 느려집니다.
        
        캐시 히트율을 높이는 것은 성능 최적화의 핵심입니다. 자주 조회되는 데이터를 캐시에 저장하거나 캐시 지역성을 고려하여 히트율을 높일 수 있습니다.
        
    - 캐시의 지역성이 뭔가요?
        
        공간 지역성 : 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하려는 특성
        
        시간 지역성 : 최근 사용한 데이터를 다시 접근하려는 특성
        
    - 캐시 교체 정책에 대해 설명해주세요.
        - FIFO, LRU
    - LRU(Least Recently Used)와 같은 캐시 정책이 항상 최선인가요? 상황에 따라 어떤 정책을 사용하는 것이 좋을까요?
        
        
    - 캐시의 동작 방식 중 쓰기 정책(Write Policy)에는 어떤 것들이 있나요?
        1. Write-Through:
            - 데이터를 캐시에 쓰는 동시에 메인 메모리에도 즉시 기록하는 방식입니다.
            - 장점: 데이터 일관성이 유지됩니다.
            - 단점: 쓰기 속도가 느려질 수 있습니다.
        2. Write-Back:
            - 데이터를 캐시에만 먼저 기록하고, 메인 메모리는 나중에 업데이트하는 방식입니다. 캐시의 데이터가 변경되면 **Dirty Bit**로 표시하고, 캐시에서 데이터가 제거될 때만 메인 메모리에 기록됩니다.
            - 장점: 쓰기 속도가 빠르고, 메인 메모리 접근 횟수를 줄일 수 있습니다.
            - 단점: 캐시 데이터 손실 시 데이터 일관성 문제가 발생할 수 있습니다.
    - 캐시 일관성을 유지하는 데 있어서 어떤 문제가 발생할 수 있나요? 이를 해결하기 위한 방법은 무엇인가요?
        - 보통 분산 시스템환경에서 해당 문제가 발생합니다.
        - 저장장치에 특정 변화가 생겼을 때, 다른 캐시에도 변경됨을 알리도록 설계
        
        캐시가 버스를 모니터링하여, 다른 코어에서 동일한 데이터에 접근하거나 변경했는지 감지합니다.
        
    - 캐시 히트율이 낮아지는 원인은 무엇이고, 이를 어떻게 분석할 수 있나요?
        1. 순차적인 접근보다 랜덤 접근이 많아질 경우 캐시 히트율이 낮아집니다.
        2. 사용하려는 데이터가 캐시에 모두 담기지 않는 경우, Capacity Miss가 증가합니다.
    - 캐시가 시스템에 부정적인 영향을 미치는 경우도 있을까요? 그런 사례가 있다면 설명해주세요.
        1. 캐시 미스가 잦거나 캐시 일관성 문제가 발생하면 데이터 읽기/쓰기 성능이 저하됩니다.
        2. 메모리 부족으로 시스템 전체 성능이 저하될 수 있습니다.
- 가상 메모리란?
    - 모든 프로세스에게 메모리를 할당하기에는 메모리에 한계가 있어 사용하는 방식입니다. 프로세스에서 사용하는 부분만 메모리에 올리고, 나머지는 디스크에 보관하는 기법입니다.
    
    - 가상 주소란?
        - Virtual Address가 없을 경우
            - 개발자로 하여금 메모리 사용에 신경써야하는 리소스 문제
            - 메모리 사용에 있어 유연성 떨어짐
        - Virtual Address가 있을 경우
            - 모든 프로세스의 메모리 시작은 0부터 무한대
            - 프로그램은 물리 메모리 주소를 알 필요가 없어짐
            - 프로세서의 MMU 장치가 가상 주소와 물리 주소를 매핑해줌
            - 메모리 사용에 있어 유연성 증가
    - MMU(Memory Management Unit) 란?
        
        프로세서 내부에 Virtual address -> physical address 컨버팅 해주는 하드웨어
        
    - 페이징이란?
        - 프로세스의 가상 주소 공간을 페이지로 나눠 물리 메모리의 프레임과 매핑하는 기법
        - 아무 페이지 프레임에나 매핑될 수 있으므로, 물리 메모리의 사용 효율을 극대화하고 외부 조각화 문제를 해결
    - 페이지 폴트란?
        
        페이지 폴트는 가상 주소 공간의 **특정 페이지**가 물리 메모리(RAM)에 아직 로드되지 않았을 때 발생합니다. 운영체제는 페이지 테이블을 통해 가상 주소와 물리 주소 간 매핑을 관리하는데, 해당 페이지가 현재 물리 메모리에 없으면 페이지 폴트가 발생하고, 디스크(예: 스왑 영역)에서 필요한 페이지를 가져와 물리 메모리에 적재합니다.
        
        가상 주소 자체가 잘못된 경우에는 **segmentation fault** 와 같은 오류가 발생한다.
        
    - 스레싱이란?
        
        메모리의 페이지 폴트율이 높은 것을 의미하며, 성능 저하를 초래합니다.
        
- 메모리 할당
    
    메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당하는데, 연속 할당과 불연속 할당으로 나뉩니다.
    
    - 연속 할당 : 메모리에 ‘연속적으로’ 공간을 할당하는 것
        - 고정 분할 방식 : 메모리를 미리 나누어 관리 → 내부 단편화 발생 (실제 할당된 공간의 빈공간이 발생)
        - 가변 분할 방식 : 프로그램 크기에 맞춰 동적으로 관리 → 외부 단편화 발생 (할당된 메모리 블록 사이에 사용되지 않은 빈 공간이 발생하는 현상)
    - 불연속 할당 : 메모리를 연속적으로 할당하지 않는 **페이징 기법**
        - 페이징 기법 : 메모리를 동일한 페이지 크기로 나누고, **프로그램마다 페이지 테이블을 두어** 메모리를 관리 → 조각화 완화
        - 세그멘테이션 : 논리적 단위인 세그멘테이션 단위로 나누는 방식 → 효율적인 할당 가능하지만, 내부 조각화 발생 가능
        - 페이지(page)와 세그먼트(segment)의 차이를 설명하시오.
            - 페이지 : 고정크기
            - 세그먼트 : 가변크기, 프로세스의 논리적 단위(스택, 코드, 데이터)에 따라 분리
        
    
- 페이지 교체 알고리즘
    
    메모리는 한정되어 있기 때문에 **스와핑**이 많이 일어납니다. 스와핑은 많이 일어나지 않도록 설계되어야 하며 이는 페이지 교체 알고리즘을 기반으로 스와핑이 일어납니다.
    
    FIFO : 
    
    LRU : Least Recently Used
    
    LFU : Least Frequently Used
    

### 프로세스와 스레드

- 프로세스와 스레드
    - 프로세스
        - 실행중인 프로그램
        - 메모리와 CPU를 프로세스마다 할당받아서 사용
    - 스레드
        - 프로세스 내부에서 실행되는 흐름 단위
        - 프로세스 안에서 다른 스레드와 메모리와 CPU를 공유
        - 스택 영역을 제외하고 모두 공유
- 프로세스 상태
        
- 프로세스 메모리 구조
        
    스택 : 매개변수, 지역변수, 함수 파라미터 (**컴파일타임에 크기 결정, but ‘동적’인 특징**)
    
    힙 : 동적할당 객체 (**런타임타임에 크기 결정**)
    
    데이터 : 전역변수, 정적변수
    
    코드 : 소스 코드
    
    - 스택과 힙 방향이 서로 반대인 이유?
        
        데이터 충돌 방지
        
- PCB
    - 프로세스에 대한 메타데이터를 저장한 데이터
    - 프로세스 생애주기와 동일
    - 프로세스 스케줄링 상태, pid, 프로그램 카운터, CPU 레지스터
- 컨텍스트 스위칭
    - PCB를 교환하는 과정
        
    - 컨텍스트 스위칭 비용
        - 유휴시간
        - 캐시 클리어로 인한 **캐시 미스**
- IPC
    - 프로세스끼리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘을 뜻합니다.
    - 클라이언트-서버간의 관계도 IPC이다.
    - 공유메모리, 소켓, 메세지큐
        - 공유메모리
            - 여러 프로세스에 동일한 메모리 블록에 대한 접근 권한이 부여되어 프로세스가 서로 통신할 수 있도록 공유 버퍼를 생성하는 것
            - 불필요한 오버헤드가 발생하지 않아 빠름
            - 동기화 이슈가 있음
        - 소켓
            - 익명 파이프 또는 명명 파이프를 통해 통신
            - 거리에 제약없음
            - 구현 복잡, 상대적으로 느림
        - 메세지큐
            - 메세지를 큐 데이터 형태로 관리
            - 사용 방법이 매우 간단
            - 순서보장
            - 추가적인 메모리 소비
        
- 뮤텍스
    
    뮤텍스는 프로세스나 스레드가 공유 자원을 `lock()`을 통해 잠금 설정하고 사용한 후에는 `unlock()`을 통해 잠금 해제하는 객체입니다.
    
- 세마포어
    - 간단한 정수값과 wait(P함수) 및 signal(V함수)로 공유자원에 대한 접근을 처리한다.
    - 바이너리 세마포어 : 뮤텍스라고 할 수 있지만, 세마포어는 ‘신호 메커니즘’이고, 뮤텍스는 ‘잠금 메커니즘’이다.
- 데드락
    1. 상호 배제 : 한 프로세스가 **자원을 독점**하고 있으며 다른 프로세스들은 접근이 불가능합니다.
    2. 점유 대기 : 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상태입니다.
    3. 비선점 : 다른 프로세스의 자원을 강제적으로 가져올 수 없습니다.
    4. 순환대기 : 서로 다른 프로세스가 서로의 자원을 요구하는 상황을 말합니다, 의존관계 순환

### CPU 스케줄링 알고리즘

- 비선점형
    
    FCFS, SJF, 우선순위 - 기아문제
    
- 선점형
    - 라운드로빈 - 너무 짧으면 오버헤드, 너무 길면 FCFS 가 됨
    - 멀티레벨 우선순위 큐 - 기아 문제를 에이징으로 해결

- 페이징 기법에서 TLB(Translation Lookaside Buffer)의 역할과 TLB 미스가 발생했을 때 처리 과정을 설명하시오.
    
    
- 뮤텍스 vs 모니터
    - 뮤텍스는 여러 프로세스 동기화 가능
    - 모니터는 하나의 프로세스 내에서 여러 동기화만 가능

<aside>

</aside>
